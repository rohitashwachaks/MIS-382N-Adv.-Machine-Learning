{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MIS 382N - HW1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "evHVxwk2JA-3"
      },
      "source": [
        "# <p style=\"text-align: center;\">MIS 382N: Advanced Machine Learning</p>\n",
        "# <p style=\"text-align: center;\">Homework 1</p>\n",
        "## <p style=\"text-align: center;\">Total points: 55</p>\n",
        "## <p style=\"text-align: center;\">Due: Wednesday, Sep 8 submitted via Canvas by 11:59 pm</p>\n",
        "\n",
        "Your homework should be written in a **Jupyter notebook**. Please make sure your code runs and the graphics (and anything else) are displayed in your notebook before submitting. (%matplotlib inline)\n",
        "\n",
        "**Note: Notebooks MUST have the images embedded in them. There will be no regrades if attached images do not render in the notebook. Please re download from canvas after submission and make sure all attached images render without errors. (Hint: Image module from IPython.display)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWWU_gOSLEEv"
      },
      "source": [
        "# Question 1: MLOps (10 pts)\n",
        "Read this [article](https://towardsdatascience.com/what-is-mlops-everything-you-must-know-to-get-started-523f2d0b8bd8) \"What is MLOps — Everything You Must Know to Get Started\", which gives a quick walkthrough of the machine learning development lifecycle and explains how MLOps come into play, or watch this [video](https://www.youtube.com/watch?v=06-AZXmwHjo) which you may find interesting.\n",
        "\n",
        "1. (**4 pts**) Use your own words to describe what MLOps is, and what challenges MLOps address. Limit your answer to one paragraph.\n",
        "\n",
        "2. (**6 pts**) Describe what the main phases in MLOps are. Your answer should be 2-3 paragraphs.\n",
        "\n",
        "\n",
        "## Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wusA9L1LmUMH"
      },
      "source": [
        "# Question 2: Applications of Machine Learning (5 pts)\n",
        "Read this [article](https://builtin.com/data-science/data-science-applications-examples) \"17 Data Science Applications & Examples\" and pick one of the data science systems used by various organizations according to this blog. \n",
        "\n",
        "For this system you have chosen, answer the following questions. Please limit your answer to one paragraph:\n",
        "\n",
        "1. What kind of machine learning problem is involved (e.g. classification, regression, clustering, outlier detection,...) in this system?\n",
        "2. Speculate on what kind of data may be needed and how the results can be useful to the organization.\n",
        "3. What do you think are the ethical implications of using machine learning in a domain like this?\n",
        "\n",
        "## Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w8za9lLmVO7"
      },
      "source": [
        "# Question 3: Simpson's Paradox (10 pts)\n",
        "A data scientist should be careful about drawing unwarranted conclusions about any data that is presented. One of the 'gotchas' that can happen even in apparently very simple tabular summaries, is called Simpson's paradox.\n",
        "\n",
        "Read this [article](https://www.covid-datascience.com/post/israeli-data-how-can-efficacy-vs-severe-disease-be-strong-when-60-of-hospitalized-are-vaccinated), which explains why the computed efficacy of the Pfizer vaccine is misleadingly low (67.5%) when you lump all people together, but once you stratify people by age (which is the right thing to do), you get much higher efficacy numbers.\n",
        "\n",
        "1.(**5 pts**) Explain in your own words what Simpson's paradox is, and how this 'paradox' can happen in real data.\n",
        "\n",
        "2.(**5 pts**) Find and mention another example of Simpson's paradox (but not any of the 3 examples given in the Wikipedia entry for 'Simpson's paradox'), state why the paradox appeared in your chosen example. Also give a reference (URL) to your source for the chosen example.\n",
        "\n",
        "## Answer:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gth0D8jiMBSe"
      },
      "source": [
        "# Question 4: Ridge and Lasso Regression (30 pts)\n",
        "\n",
        "Download the dataset **Admission.csv** from Canvas and use the following codes to import the Admission dataset in Python. \n",
        "\n",
        "There are 7 features in the dataset:\n",
        "\n",
        "1. GRE score\n",
        "2. TOEFL score\n",
        "3. University Rating\n",
        "4. SOP(Statement of Purpose)\n",
        "5. LOR(Letter of Recommendation)\n",
        "6. CGPA\n",
        "7. Research\n",
        "\n",
        "And the target is **Chance of Admission**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFazlpLgGpAa"
      },
      "source": [
        "# Only use this code block if you are using Google Colab.\n",
        "# If you are using Jupyter Notebook, please ignore this code block. You can directly upload the file to your Jupyter Notebook file systems.\n",
        "from google.colab import files\n",
        "\n",
        "## It will prompt you to select a local file. Click on “Choose Files” then select and upload the file. \n",
        "## Wait for the file to be 100% uploaded. You should see the name of the file once Colab has uploaded it.\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsPaOOehGuU6"
      },
      "source": [
        "# Codes below will work for both Google Colab and Jupyter Notebook.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "## Load the dataset into pandas DataFrame\n",
        "df = pd.read_csv('Admission.csv', index_col=0)\n",
        "df = df.replace([np.inf, -np.inf], np.nan) # \n",
        "df = df.fillna(0) # Replace all the NaN values with 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmMz72U6Gv-z"
      },
      "source": [
        "df.columns # Show you all the columns in this file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyZN-yFfGxlt"
      },
      "source": [
        "df.head() # Show you the first 5 rows in this file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3TfR0i4G2rO"
      },
      "source": [
        "y = df['Chance_of_Admit'] # The column named Chance_of_Admit is used as the target, and we store it in y\n",
        "X = df.drop(['Chance_of_Admit'], axis=1) # We keep the remaining columns as the features, and store them in x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pKq1KERxJw9y"
      },
      "source": [
        "1)(**2 pts**) Split the data into a training set(75% of data) and a test set(25% of data), using the [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function with random_state = 50. Then scale the data (not including target) so that each of the independent variables would have zero mean and unit variance. You can use the [sklearn.preprocessing.scale](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html) function for this. Print the first 5 rows of the training set after scaling.\n",
        "\n",
        "2)(**5 pts**) Use [sklearn.linear_model.Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html) and [sklearn.linear_model.Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html) classes to do a **5-fold** cross validation using sklearn's KFold. For the sweep of the regularization parameter, we will look at a grid of values ranging from α=10^10 to α=10^−6. In Python, you can consider this range of values as follows: alpha = 10**numpy.linspace(6,-6,100) \n",
        "so that you can generate 100 uniform values between -6 to 6 as power series.\n",
        "\n",
        "Fit the 2 regression models with scaled data and report the best chosen **α** based on cross validation as well as the corresponding scoring metric. The cross validation should happen on your training data using **MSE** as the scoring metric.\n",
        "\n",
        "3)(**5 pts**) Run ridge and lasso regression for all of the **α** specified above (on training data), and plot the coefficients learned for each of them - there should be one plot each for lasso and ridge, so a total of two plots; different features' weights of each model should be on the same plot with different colors (3pts). \n",
        "\n",
        "What do you qualitatively observe when the value of the regularization parameter changes (2pts)? \n",
        "\n",
        "4)(**3 pts**) Take the exponential of Y_train as the target, and fit the 2 regression models again. Report the best chosen **α** based on cross validation as well as the corresponding scoring metric. Compare the results of using the original target with the results of using the exponential of the target. What do you observe? \n",
        "\n",
        "5)(**5 pts**) Similarly, use [sklearn.linear_model.ElasticNet](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html) to do linear regression with different **α** values, and plot the coefficients learned for each of them (2pts). Observe the plot, then explain the pros and cons of ridge, lasso and Elastic Net models (3pts).\n",
        "\n",
        "\n",
        "6)(**5 pts**) Run the following three regression models with **MSE** loss on the training data: \n",
        "\n",
        "a. linear regression without regularization (1pts)\n",
        "\n",
        "b. linear regression with ridge regularization (2pts)\n",
        "\n",
        "c. linear regression with lasso regularization (2pts)\n",
        "\n",
        "For part (b) and (c), use only the best regularization parameters. Report the MSE and R<sup>2</sup> on the test data for each model.\n",
        "\n",
        "7)(**5 pts**) Train the 3 models and report the metrics with the original data without scaling (3pts). \n",
        "\n",
        "Why do we need to scale the data before regularization (2pts)? \n",
        "\n",
        "## Answer:\n"
      ]
    }
  ]
}